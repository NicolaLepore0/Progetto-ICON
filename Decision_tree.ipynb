{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "import graphviz\n",
    "import numpy as np\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m      2\u001B[0m tf\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mset_visible_devices([], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGPU\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\untitled\\lib\\site-packages\\tensorflow\\__init__.py:37\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_typing\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_util \u001B[38;5;28;01mas\u001B[39;00m _module_util\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LazyLoader \u001B[38;5;28;01mas\u001B[39;00m _LazyLoader\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\untitled\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# pylint: enable=wildcard-import\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# Bring in subpackages.\u001B[39;00m\n\u001B[1;32m---> 42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# from tensorflow.python import keras\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\untitled\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m experimental\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AUTOTUNE\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\untitled\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:126\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlookup_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m index_table_from_dataset\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlookup_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m table_from_dataset\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparsing_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse_example_dataset\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprefetching_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m copy_to_device\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprefetching_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m prefetch_to_device\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\untitled\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\parsing_ops.py:22\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_spec\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m gen_experimental_dataset_ops\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parsing_ops\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mragged\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ragged_tensor\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtf_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf_export\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\untitled\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py:23\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m gen_parsing_ops\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m math_ops\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parsing_config\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# go/tf-wildcard-import\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# pylint: disable=wildcard-import,undefined-variable\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgen_parsing_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\untitled\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_config.py:28\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m math_ops\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sparse_ops\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mragged\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ragged_math_ops\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mragged\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ragged_tensor\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplatform\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf_logging\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1002\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:945\u001B[0m, in \u001B[0;36m_find_spec\u001B[1;34m(name, path, target)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:1439\u001B[0m, in \u001B[0;36mfind_spec\u001B[1;34m(cls, fullname, path, target)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:1411\u001B[0m, in \u001B[0;36m_get_spec\u001B[1;34m(cls, fullname, path, target)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:1544\u001B[0m, in \u001B[0;36mfind_spec\u001B[1;34m(self, fullname, target)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:147\u001B[0m, in \u001B[0;36m_path_stat\u001B[1;34m(path)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "conda install -c anaconda python-graphviz\n",
    "\n",
    "conda install -c anaconda pydot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "giocatori = pd.read_csv('dataset\\giocatori.csv')\n",
    "\n",
    "giocatori = giocatori.drop('nome_giocatore', axis = 1)\n",
    "giocatori = giocatori.drop('numero_giocatore', axis = 1)\n",
    "giocatori = giocatori.drop('squadra', axis = 1)\n",
    "giocatori = giocatori.drop('RIM_D', axis = 1)\n",
    "giocatori = giocatori.drop('RIM_O', axis = 1)\n",
    "giocatori = giocatori.drop('T1_PER', axis = 1)\n",
    "giocatori = giocatori.drop('T2_PER', axis = 1)\n",
    "giocatori = giocatori.drop('T3_PER', axis = 1)\n",
    "\n",
    "players_without_role = giocatori.loc[(giocatori[\"ruolo\"].isnull()) | (giocatori[\"ruolo\"] == \"NaN\")]\n",
    "players_without_role = players_without_role.drop('ruolo', axis = 1)\n",
    "\n",
    "giocatori = giocatori.dropna();\n",
    "\n",
    "# Definire una funzione per scalare i valori di ogni riga\n",
    "def scale_cols(df, col):\n",
    "    df = df[df[col] != 0]\n",
    "    factor = 40/df[col].values\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns\n",
    "    float_cols = float_cols.drop(col)\n",
    "    df.loc[:, float_cols] = df[float_cols].mul(factor, axis=0)\n",
    "    return df\n",
    "\n",
    "players_without_role = scale_cols(players_without_role, 'minuti')\n",
    "players_without_role = players_without_role.drop('minuti', axis = 1)\n",
    "players_without_role[\"altezza\"] = players_without_role[\"altezza\"].replace(0, np.nan, inplace=True)\n",
    "\n",
    "giocatori = scale_cols(giocatori, 'minuti')\n",
    "giocatori = giocatori.drop('minuti', axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = giocatori.drop('ruolo', axis=1)\n",
    "y = giocatori['ruolo']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1,random_state=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [3, 5, 7, 9,11,None],\n",
    "              'min_samples_split': [2, 10, 30, 50]}\n",
    "\n",
    "grid_search = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(x, y)\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score: %0.2f\" % grid_search.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree.plot_tree(clf)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Esportazione albero di decisione\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"ruoli_tree\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Quasto modello non può lavorare con valori nulli. Dunque si scarta in caso si abbiano giocatori con valori nulli.\n",
    "#y_pred = grid_search.predict(players_without_role)\n",
    "#print(players_without_role.values)\n",
    "#print(y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "HGBC = HistGradientBoostingClassifier(max_iter=150, learning_rate=0.1)\n",
    "HGBC.fit(x, y)\n",
    "\n",
    "scores = cross_val_score(HGBC, x, y, cv=5)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = HGBC.predict(players_without_role)\n",
    "print(y_pred)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Define a range of values to test for max_depth\n",
    "max_depth_values = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Define a range of values to test for random_state\n",
    "random_state_values = [0, 4, 16, 64, 256, 1024,4096]\n",
    "\n",
    "# Store the mean cross-validation scores for each combination of max_depth and random_state\n",
    "scores = []\n",
    "for max_depth in max_depth_values:\n",
    "    for random_state in random_state_values:\n",
    "        RFC = RandomForestClassifier(max_depth=max_depth, random_state=random_state)\n",
    "        cv_scores = cross_val_score(RFC, x, y, cv=5)\n",
    "        scores.append((max_depth, random_state, cv_scores.mean()))\n",
    "\n",
    "# Convert the scores list to a numpy array\n",
    "scores = np.array(scores)\n",
    "\n",
    "# Get the index of the maximum score\n",
    "best_index = np.argmax(scores[:,2])\n",
    "\n",
    "# Get the best max_depth and random_state values\n",
    "best_max_depth = scores[best_index, 0]\n",
    "best_random_state = scores[best_index, 1]\n",
    "\n",
    "# Print the best max_depth and random_state values\n",
    "print(\"Best max_depth value: {}\".format(best_max_depth))\n",
    "print(\"Best random_state value: {}\".format(best_random_state))\n",
    "\n",
    "RFC = RandomForestClassifier(max_depth=int(best_max_depth), random_state=int(best_random_state))\n",
    "RFC.fit(x, y)\n",
    "scores = cross_val_score(RFC, x, y, cv=5)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f} +/- {:.2f}\".format(scores.mean(), scores.std()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Non funziona con valori nulli\n",
    "#y_pred = RFC.predict(players_without_role)\n",
    "#print(y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Predict the labels of the test data\n",
    "y_pred = RFC.predict(x_test)\n",
    "\n",
    "# Calculate the accuracy on the test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Se non scalo la x non converge.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_scal = scaler.fit_transform(x)\n",
    "#########\n",
    "LR = LogisticRegression(max_iter=1000)\n",
    "LR.fit(x_scal, y)\n",
    "\n",
    "scores = cross_val_score(LR, x_scal, y, cv=5)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Effettua la codifica one-hot, rende y un vettore [0,0,0,0]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "Y = to_categorical(y)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def create_model(neurons_first_layer, neurons_second_layer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_first_layer, activation='relu', input_shape=(15,)))\n",
    "    model.add(Dense(neurons_second_layer, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=1000, batch_size=32, verbose=0)\n",
    "\n",
    "neurons_first_layer = [32, 64, 128]\n",
    "neurons_second_layer = [16, 32, 64]\n",
    "param_grid = dict(neurons_first_layer=neurons_first_layer, neurons_second_layer=neurons_second_layer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(x, Y)\n",
    "\n",
    "# Stampa dei risultati\n",
    "print(\"Migliori parametri: \", grid_result.best_params_)\n",
    "print(\"Miglior punteggio: \", grid_result.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Accuratezza: %.2f' % (grid.score(x, Y)*100))\n",
    "#print('Accuratezza: %.2f' % (accuracy*100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "prova = imputer.fit_transform(players_without_role)\n",
    "y_pred = grid.predict(players_without_role)\n",
    "def predizione(pred):\n",
    "    strings = [\"Ala\", \"Play\", \"Centro\", \"Guardia\"]\n",
    "    return [strings[np.argmax(vector)] for vector in pred]\n",
    "\n",
    "print(predizione(y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_22244\\1252135091.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, float_cols] = df[float_cols].mul(factor, axis=0)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 55\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# Seleziona le colonne che vuoi utilizzare come feature\u001B[39;00m\n\u001B[0;32m     53\u001B[0m features \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maltezza\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mT2_T\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mT2_PER\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mT3_T\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mT3_PER\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRIM_O\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRIM_D\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRIM_T\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTOP_D\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTOP_S\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mASS\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 55\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mgiocatori\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# Inizializza il modello K-means con un numero di cluster definito (ad esempio, 5 cluster)\u001B[39;00m\n\u001B[0;32m     58\u001B[0m kmeans \u001B[38;5;241m=\u001B[39m KMeans(n_clusters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, n_init\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
      "\u001B[1;31mIndexError\u001B[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "# Carica il dataset in un dataframe di pandas\n",
    "giocatori = pd.read_csv(\"dataset/giocatori.csv\")\n",
    "giocatori = giocatori.drop('nome_giocatore', axis = 1)\n",
    "giocatori = giocatori.drop('numero_giocatore', axis = 1)\n",
    "giocatori = giocatori.drop('squadra', axis = 1)\n",
    "\n",
    "def replace_role(row):\n",
    "    if row['ruolo'] == 'Centro':\n",
    "        return 0\n",
    "    elif row['ruolo'] == 'Ala':\n",
    "        return 1\n",
    "    elif row['ruolo'] == 'Guardia':\n",
    "        return 2\n",
    "    elif row['ruolo'] == 'Play':\n",
    "        return 3\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "giocatori['ruolo'] = giocatori.apply(replace_role, axis=1)\n",
    "\n",
    "# Definire una funzione per scalare i valori di ogni riga\n",
    "def scale_cols(df, col):\n",
    "    df = df[df[col] != 0]\n",
    "    factor = 40/df[col].values\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns\n",
    "    float_cols = float_cols.drop(col)\n",
    "    df.loc[:, float_cols] = df[float_cols].mul(factor, axis=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "giocatori = scale_cols(giocatori, 'minuti')\n",
    "\n",
    "# inizializza il scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# calcola i valori minimi e massimi per ogni colonna\n",
    "scaler.fit(giocatori)\n",
    "\n",
    "# normalizza i valori del dataset\n",
    "giocatori = scaler.transform(giocatori)\n",
    "\n",
    "\n",
    "# Seleziona le colonne che vuoi utilizzare come feature\n",
    "features = ['altezza','T2_T', 'T2_PER','T3_T', 'T3_PER', 'RIM_O', 'RIM_D', 'RIM_T', 'STOP_D', 'STOP_S','ASS']\n",
    "\n",
    "X = giocatori[features].values\n",
    "\n",
    "# Inizializza il modello K-means con un numero di cluster definito (ad esempio, 5 cluster)\n",
    "kmeans = KMeans(n_clusters=4, n_init=10)\n",
    "\n",
    "# Fit il modello sui dati\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Prevedi i cluster a cui appartengono ogni giocatore\n",
    "labels = kmeans.predict(X)\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_score = silhouette_score(X, labels)\n",
    "print(\"Silhouette Score: \", silhouette_score)\n",
    "\n",
    "print(labels[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
